<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>PhO-Compress Atom-LLM — O(M) Lineares Modell (FINAL, Debug &amp; Local en_US)</title>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu@4.22.0/dist/tf-backend-webgpu.min.js"></script>

  <style>
    body{background:#f5f6f8;color:#1f2937;font-family:ui-sans-serif,-apple-system,Segoe UI,Roboto,Helvetica,Arial}
    .container{max-width:1100px;margin:32px auto;padding:0 16px}
    .card{background:#fff;border:1px solid #e5e7eb;border-radius:14px;box-shadow:0 1px 2px rgba(0,0,0,.04);padding:18px;margin:16px 0}
    .row{display:grid;gap:12px}
    @media(min-width:1000px){.row{grid-template-columns:1fr 1fr}}
    textarea,input,button,select{font-family:inherit}
    textarea{width:100%;min-height:140px;border:1px solid #d1d5db;border-radius:10px;padding:10px}
    input,select{width:100%;border:1px solid #d1d5db;border-radius:10px;padding:8px}
    label{font-size:12px;color:#6b7280;margin-bottom:4px;display:block}
    .btn{background:#4f46e5;border:none;color:#fff;border-radius:10px;padding:10px 14px;font-weight:600;cursor:pointer}
    .btn.secondary{background:#059669}
    .btn.grey{background:#6b7280}
    .btn.warn{background:#f59e0b}
    .btn.red{background:#ef4444}
    .btn:disabled{opacity:.5;cursor:not-allowed}
    .log{height:220px;overflow:auto;background:#0b1020;color:#d1d5db;border-radius:10px;padding:10px;font-family:ui-monospace,Menlo,Consolas,monospace;font-size:12px}
    .mono{font-family:ui-monospace,Menlo,Consolas,monospace; word-break: break-word; white-space: pre-wrap;}
    .muted{color:#6b7280}
    .spinner{border:4px solid rgba(0,0,0,.1);border-left-color:#4f46e5;border-radius:50%;width:20px;height:20px;animation:spin .8s linear infinite;display:inline-block}
    @keyframes spin{to{transform:rotate(360deg)}}
    .kpi{display:flex;gap:10px;flex-wrap:wrap}
    .kpi div{background:#f9fafb;border:1px solid #e5e7eb;border-radius:10px;padding:8px 10px}
    .row4{display:grid;grid-template-columns:repeat(4,1fr);gap:12px}
    
    /* Manuelle Tailwind-Utility-Klassen, die im HTML verwendet werden */
    .mb-1{margin-bottom:0.25rem}
    .mb-2{margin-bottom:0.5rem}
    .mb-4{margin-bottom:1rem}
    .mt-2{margin-top:0.5rem}
    .mt-3{margin-top:0.75rem}
    .flex{display:flex}
    .items-end{align-items:flex-end}
    .items-center{align-items:center}
    .gap-3{gap:0.75rem}
    .text-2xl{font-size:1.5rem;line-height:2rem}
    .text-lg{font-size:1.125rem;line-height:1.75rem}
    .font-bold{font-weight:700}
    .font-extrabold{font-weight:800}
  </style>
</head>
<body>
<div class="container">
  <h1 class="text-2xl font-extrabold mb-1">PhO-Compress Atom-LLM ($O(M)$ Lineare Skalierung)</h1>
  <div class="muted mb-4">Lokal: <b>/data/en_US.txt</b> (ipa-dict Text), <b>Datei-Export/Import</b>, Debug-Tools. Keine IPA-Regel-Hacks.</div>

  <div class="card">
    <h3 class="font-bold text-lg mb-2">1) Korpus &amp; G2P → IPA (lokales Wörterbuch)</h3>
    <textarea id="txt" placeholder="Füge einen ENGLISCHEN Textkorpus ein …"></textarea>

    <div class="row" style="margin-top:10px">
      <div>
        <label>Atom-Vokabular (Ziel)</label>
        <input id="atomVocab" type="number" min="64" max="1024" step="32" value="512">
      </div>
      <div>
        <label>Max. Kontext M (Lineares Modell)</label>
        <input id="seqLen" type="number" min="64" max="768" step="32" value="128">
      </div>
    </div>

    <div class="row" style="margin-top:10px">
      <div class="flex items-center gap-3">
        <button id="btnLoadDict" class="btn grey">en_US.txt laden</button>
        <button id="btnBuildIPA" class="btn grey" disabled>1. G2P → IPA erzeugen</button>
        <button id="btnTrainAtoms" class="btn warn" disabled>2. Atome lernen (BPE auf IPA)</button>
      </div>
      <div class="flex items-center gap-3">
        <button id="btnClear" class="btn red">Alles zurücksetzen</button>
        <button id="btnDbgDump" class="btn">Debug Dump</button>
      </div>
    </div>

    <div class="kpi mt-3">
      <div id="kpiDict" class="muted">Wörterbuch: –</div>
      <div id="kpiIPA" class="muted">IPA: –</div>
      <div id="kpiAtoms" class="muted">Atome: –</div>
      <div id="kpiComp" class="muted">Kompression: –</div>
    </div>
  </div>

  <div class="card">
    <h3 class="font-bold text-lg mb-2">2) Lineares Modell Setup &amp; Training</h3>
    <div class="row4">
      <div><label>Schichten L</label><input id="nLayers" type="number" min="1" max="8" value="3"></div>
      <div><label>d_model</label><input id="dModel" type="number" min="64" max="512" step="32" value="256"></div>
      <div><label>FFN-Dim</label><input id="dFF" type="number" min="128" max="2048" step="64" value="512"></div>
      <div><label>Epochen</label><input id="epochs" type="number" min="1" max="40" value="4"></div>
    </div>

    <div class="row4 mt-3">
      <div><label>LR (Adam)</label><input id="lr" type="number" min="0.00005" max="0.02" step="0.00005" value="0.002"></div>
      <div><label>Batchgröße</label><input id="batch" type="number" min="8" max="128" step="8" value="32"></div>
      <div><label>Steps/Epoche (0=auto)</label><input id="stepCap" type="number" min="0" max="50000" step="100" value="400"></div>
      <div class="flex items-end gap-3">
        <label class="muted"><input id="useGPU" type="checkbox" checked=""> WebGPU bevorzugen</label>
        <label class="muted"><input id="useDropout" type="checkbox"> Dropout 0.1</label>
        <label class="muted"><input id="autoLR" type="checkbox" checked=""> Auto-LR</label>
      </div>
    </div>

    <div class="flex items-center gap-3 mt-3">
      <button id="btnTrain" class="btn" disabled>
        <span id="trainText">3. Training starten</span>
        <span id="spin" class="spinner" style="display: none; margin-left: 8px;"></span>
      </button>
      <button id="btnStop" class="btn red" disabled>Stop</button>

      <button id="btnExport" class="btn warn" disabled>Modell exportieren (Datei)</button>
      <label class="btn secondary" for="fileImport" style="cursor:pointer">Modell importieren (Datei)</label>
      <input id="fileImport" type="file" accept="application/json" style="display:none">

      <div id="stats" class="muted">V=512 • M=128 • B=32 • L=3 • d=128 • dFF=512 • Steps/Ep=400</div>
    </div>
  </div>

  <div class="card">
    <h3 class="font-bold text-lg mb-2">3) Inferenz (Atom → IPA)</h3>
    <textarea id="prompt" placeholder="Prompt (Text) eingeben … (Enter zum Senden, Shift+Enter für Zeilenumbruch)" disabled></textarea>
    <div class="row">
      <div><label>Sampling-Modus</label>
        <select id="sampleMode">
          <option value="topp" selected="">Top-p</option>
          <option value="topk">Top-k</option>
        </select>
      </div>
      <div><label>Top-k</label><input id="topK" type="number" min="1" max="200" value="64" disabled></div>
      <div><label>Top-p</label><input id="topP" type="number" min="0.05" max="1.0" step="0.05" value="0.9"></div>
      <div><label>Temperatur</label><input id="temp" type="number" min="0.1" max="2.0" step="0.1" value="0.9"></div>
    </div>
    <div class="row mt-2">
      <div><label>Tokens generieren</label><input id="nGen" type="number" min="1" max="2000" value="200"></div>
      <div class="flex items-end gap-3">
        <button id="btnGen" class="btn secondary" disabled>Generieren</button>
        <button id="btnStopGen" class="btn red" disabled>Stop</button>
        <div id="inferStats" class="muted">Tokens: 0 • Latenz 0.0 ms</div>
      </div>
    </div>
    
    <div class="mt-3">
      <div class="muted mb-1">Ausgabe (Text, mit Fuzzy-Matching)</div>
      <div id="outText" class="mono" style="white-space:pre-wrap;background:#fff;border:1px solid #c5d7f8;border-radius:10px;padding:10px;min-height:80px; font-size: 1.1em; line-height: 1.6;"></div>
    </div>
    
    <div class="mt-3">
      <div class="muted mb-1">Ausgabe (IPA, Roh-Debug)</div>
      <div id="outIPA" class="mono" style="white-space:pre-wrap;background:#f9fafb;border:1px solid #e5e7eb;border-radius:10px;padding:10px;min-height:80px; font-size: 0.9em; color: #6b7280;"></div>
    </div>
  </div>

  <div class="card">
    <h3 class="font-bold text-lg mb-2">Perplexity &amp; Log</h3>
    <div id="metrics" class="muted mb-2"><b>Epoche –/–</b> &nbsp; Loss=– &nbsp; Val PPL=– &nbsp; ~Tok/s=– &nbsp; LR=–</div>
    <div id="log" class="log">[Log bereit. Lineares $O(M)$-Modell aktiviert.]</div>
  </div>
</div>

<script>
/* =================== Core & Debug =================== */
const $ = id => document.getElementById(id);
const MAX_LOG_CHARS = 120000;
const BOS_ID = 0, EOS_ID = 1;

const STATE = {
  dict: new Map(),   // en_US.txt Inhalte
  ipa: '',           // gesamter IPA-String des Korpus
  atomizer: null,    // {encodeIPAtoAtoms, decodeAtomsToIPA, ...}
  tokens: null,      // Uint32Array
  model: null,
  modelRev: 0,
  cancelTrain: false,
  cancelGen: false
};
window.STATE = STATE; // für DevTools

function logLine(msg){
  const el = $('log');
  const line = `[${new Date().toLocaleTimeString()}] ${msg}\n`;
  el.textContent = line + el.textContent;
  if (el.textContent.length > MAX_LOG_CHARS) el.textContent = el.textContent.slice(0, MAX_LOG_CHARS);
}
function clamp(v, lo, hi){ v = Number.isFinite(v) ? v : lo; return Math.max(lo, Math.min(hi, v)); }
function valNum(id, fallback, lo=null, hi=null){
  const el = $(id);
  let v = Number(el?.value);
  if(!Number.isFinite(v)) v = fallback;
  if(lo!=null) v = Math.max(lo, v);
  if(hi!=null) v = Math.min(hi, v);
  return v;
}
function valBool(id, fallback=false){ return $(id)?.checked ?? fallback; }

function setButtonState(id, disabled, text, showSpinner=false) {
  const btn = $(id); if (!btn) return;
  btn.disabled = !!disabled;
  if (id === 'btnTrain') {
    const labelEl = btn.querySelector('span#trainText');
    if (labelEl && text != null) labelEl.textContent = String(text);
    const spinEl = btn.querySelector('span#spin');
    if (spinEl) spinEl.style.display = showSpinner ? 'inline-block' : 'none';
  } else {
    const span = btn.querySelector('span');
    if (span && text != null) span.textContent = String(text);
    else if (text != null) btn.textContent = String(text);
  }
}
async function microYield(){
  // kurze Entlastung fürs UI + TFJS Engine (siehe tf.nextFrame)
  await new Promise(r=>setTimeout(r,0));
  await tf.nextFrame();
}
function dbgState(tag=''){
  const A = STATE.atomizer;
  const T = STATE.tokens;
  logLine(`[DBG ${tag}] atomizer=${!!A} vocab=${A?.vocabSize ?? '–'} merges=${A?.merges?.length ?? '–'} | tokens=${T ? (T.length+' (Uint32Array='+ (T instanceof Uint32Array)+')') : 'null'} | ipaLen=${STATE.ipa?.length ?? 0}`);
}

/* =================== Wörterbuch: /data/en_US.txt =================== */
/* Format robust parsen:
   - Zeilenweise: word /ipa1/, /ipa2/  ODER  word\tipa  ODER  word<space>ipa
   - Kommentare (# ...) und leere Zeilen ignorieren.
*/
async function loadLocalDictEN(){
  const url = '/data/en_US.txt';
  const r = await fetch(url, {mode:'same-origin'});
  if (!r.ok) throw new Error(`HTTP ${r.status}`);
  const text = await r.text();
  const map = new Map();
  const lines = text.split(/\r?\n/);
  let add=0, dup=0;
  for (let line of lines){
    line = line.trim();
    if (!line || line.startsWith('#')) continue;

    // Muster A: word /ipa1/, /ipa2/
    let m = line.match(/^([^\s/]+)\s+(.+)$/);
    if (m){
      const w = m[1].toLowerCase();
      let rest = m[2].trim();

      // Falls /ipa/ Kommaliste
      const iph = [];
      const slashParts = rest.match(/\/[^/]+\/(,\s*\/[^/]+\/)*/);
      if (slashParts){
        // Split bei /.../ , /.../
        const tmp = rest.split(/,\s*/).map(s=>s.trim());
        for (const t of tmp){
          const mm = t.match(/^\/([^/]+)\/$/);
          if (mm) iph.push(mm[1].trim());
        }
      } else {
        // Kein Slash-Format, nimm kompletten Rest als IPA
        iph.push(rest);
      }
      if (!map.has(w)) { map.set(w, iph.join(' / ')); add++; } else dup++;
      continue;
    }
  }
  STATE.dict = map;
  $('kpiDict').textContent = `Wörterbuch geladen: en_US (words=${map.size}, added=${add}, dup=${dup})`;
  logLine(`Wörterbuch geladen: en_US (words=${map.size}, added=${add}, dup=${dup})`);
}

const WORD_RE = /[\p{L}\p{M}\p{Nd}]+/u;
function tokenize(text){
  const m = text.normalize('NFC').match(/[\p{L}\p{M}\p{Nd}]+|[^\s]/gu) || [];
  return m.map(s=>s.toString());
}

function g2pConvert(text){
  if (STATE.dict.size===0) throw new Error('IPA-Wörterbuch nicht geladen (/data/en_US.txt).');
  const toks = tokenize(text.toLowerCase());
  const out = [];
  for (const t of toks){
    if (!WORD_RE.test(t)){ out.push(t); continue; } // Satzzeichen etc.
    const hit = STATE.dict.get(t);
    if (hit){ out.push(hit); }
    else { out.push(`‹${t}›`); } // bewusst keine Regel-Hacks
  }
  return out.join(' ').replace(/\s+/g,' ').trim();
}

/* =================== Atomizer (BPE) — keine Parallelität =================== */
function strToCodepoints(str){ const arr = []; for (let i=0;i<str.length;i++) arr.push(str.charCodeAt(i)); return arr; }
function codepointsToStr(arr){ return String.fromCharCode(...arr); }

function buildAtomBPE(rawIPA, targetVocab=512){
  return new Promise(async (resolve) => {
    const cps = strToCodepoints(rawIPA);
    const uniq = Array.from(new Set(cps.filter(x=>!Number.isNaN(x)))).sort((a,b)=>a-b);
    const cp2id = new Map(); const id2cp = new Map();
    let nextId = 2; // 0 BOS, 1 EOS reserviert
    for (const c of uniq){ cp2id.set(c,nextId); id2cp.set(nextId,c); nextId++; }
    let seq = cps.map(c => cp2id.get(c) ?? BOS_ID);

    const merges = [];
    const baseVocab = nextId;

    function countPairs(sequence){
      const counts = new Map();
      for (let i=0;i<sequence.length-1;i++){
        const key = sequence[i] + ',' + sequence[i+1];
        counts.set(key, (counts.get(key)||0) + 1);
      }
      return counts;
    }
    function applyBestPair(sequence, a, b, newId){
      const out = [];
      for (let i=0;i<sequence.length;){
        if (i<sequence.length-1 && sequence[i]===a && sequence[i+1]===b){ out.push(newId); i+=2; }
        else { out.push(sequence[i]); i+=1; }
      }
      return out;
    }

    const target = Math.max(baseVocab+10, Math.min(targetVocab, 4096));
    for (let step=0; step<(target - baseVocab); step++){
      if ((step % 32) === 0) { $('inferStats').textContent = `BPE: ${step+1}/${target-baseVocab}`; await microYield(); }
      const counts = countPairs(seq);
      if (counts.size===0) break;
      let bestKey=null, bestCnt=0;
      for (const [k,c] of counts){ if (c>bestCnt){ bestCnt=c; bestKey=k; } }
      if (!bestKey) break;
      const [aStr,bStr] = bestKey.split(',');
      const a=parseInt(aStr,10), b=parseInt(bStr,10);
      const id = nextId++;
      merges.push({a,b,id});
      seq = applyBestPair(seq, a, b, id);
      if ((step % 128) === 0) logLine(`BPE merge ${step+1}: (${a},${b}) → ${id} (count=${bestCnt})`);
    }

    function encodeIPAtoAtoms(str, addBos=false, addEos=false){
      const seq0 = strToCodepoints(str).map(c => cp2id.get(c));
      let tokens = seq0.filter(v=>Number.isFinite(v));
      for (const m of merges){
        const {a,b,id} = m;
        const out = [];
        for (let i=0;i<tokens.length;){
          if (i<tokens.length-1 && tokens[i]===a && tokens[i+1]===b){ out.push(id); i+=2; }
          else { out.push(tokens[i]); i++; }
        }
        tokens = out;
      }
      if (addBos) tokens = [BOS_ID, ...tokens];
      if (addEos) tokens = [...tokens, EOS_ID];
      return tokens;
    }
    function decodeAtomsToIPA(tokens){
      const id2pair = new Map(merges.map(m=>[m.id,[m.a,m.b]]));
      function expand(id){
        if (id===BOS_ID || id===EOS_ID) return [];
        if (id2cp.has(id)) return [ id2cp.get(id) ];
        const pr = id2pair.get(id);
        if (!pr) return [];
        return expand(pr[0]).concat(expand(pr[1]));
      }
      const cpsOut = [];
      for (const t of tokens){
        if (t===BOS_ID || t===EOS_ID) continue;
        if (id2cp.has(t)) cpsOut.push(id2cp.get(t));
        else cpsOut.push(...expand(t));
      }
      return codepointsToStr(cpsOut);
    }

    const vocabSize = nextId;
    resolve({ encodeIPAtoAtoms, decodeAtomsToIPA, vocabSize, merges, cp2id, id2cp });
  });
}

/* =================== Modell =================== */
function rmsNorm(x, gamma, eps=1e-5){
  const meanSq = tf.mean(tf.square(x), -1, true);
  const xhat = tf.div(x, tf.sqrt(tf.add(meanSq, eps)));
  return tf.mul(xhat, gamma);
}
function sinusoidalPositionalEncoding(T, d){
  const pos = tf.range(0, T, 1, 'float32');
  const half = Math.floor(d/2);
  const i2 = tf.range(0, half, 1, 'float32');
  const div = tf.exp(tf.mul(i2, tf.scalar(-Math.log(10000.0)/(Math.max(1,half-1)))));
  const ang = pos.reshape([T,1]).matMul(div.reshape([1,half]));
  const sin = tf.sin(ang), cos=tf.cos(ang);
  let pe = tf.concat([sin, cos], -1);
  if(2*half < d){ const pad = tf.zeros([T, d-2*half]); pe = tf.concat([pe, pad], -1); }
  return pe;
}
function softmaxCEfromLogits(logits, targets){
  const [B,T,V] = logits.shape;
  const oneHot = tf.oneHot(targets.toInt(), V).reshape([B*T, V]);
  const logits2d = logits.reshape([B*T, V]);
  const lossPer = tf.losses.softmaxCrossEntropy(oneHot, logits2d);
  return tf.mean(lossPer);
}

function buildModel(cfg){
  const { V, dModel, dFF, nLayers, T, weightTying=true, dropoutTrain } = cfg;

  const E = tf.variable(tf.randomNormal([V, dModel], 0, 0.02, 'float32'), true, 'E');
  const pe = sinusoidalPositionalEncoding(T, dModel);

  const layers = [];
  const CONV_KERNEL_SIZE = 5;
  for(let l=0;l<nLayers;l++){
    layers.push({
      g1: tf.variable(tf.ones([dModel]), true, `L${l}_g1`),
      g2: tf.variable(tf.ones([dModel]), true, `L${l}_g2`),
      W_Conv: tf.variable(tf.randomNormal([CONV_KERNEL_SIZE, dModel, dModel], 0, Math.sqrt(2/(dModel+dModel))), true, `L${l}_W_Conv`),
      W_Gate: tf.variable(tf.randomNormal([dModel, dModel], 0, Math.sqrt(2/(dModel+dModel))), true, `L${l}_W_Gate`),
      b_Gate: tf.variable(tf.zeros([dModel]), true, `L${l}_b_Gate`),
      W1: tf.variable(tf.randomNormal([dModel, dFF], 0, Math.sqrt(2/(dModel+dFF))), true, `L${l}_W1`),
      b1: tf.variable(tf.zeros([dFF]), true, `L${l}_b1`),
      W2: tf.variable(tf.randomNormal([dFF, dModel], 0, Math.sqrt(2/(dFF+dModel))), true, `L${l}_W2`),
      b2: tf.variable(tf.zeros([dModel]), true, `L${l}_b2`),
    });
  }

  const bout = tf.variable(tf.zeros([V]), true, 'bout');
  const W_out = tf.variable(tf.randomNormal([dModel, V], 0, 0.02, 'float32'), true, 'W_out');

  const params = {E, layers, bout, pe, cfg, W_out, CONV_KERNEL_SIZE};

  function dropout(x, rate){
    if(!dropoutTrain || rate<=0) return x;
    const keep = 1-rate;
    const m = tf.randomUniform(x.shape,'float32').greater(tf.scalar(rate)).toFloat();
    return tf.mul(x, tf.div(m, tf.scalar(keep)));
  }

  function forward(ids, training=true){
    return tf.tidy(() => {
      const B = ids.shape[0], Tcur = ids.shape[1], dM = params.cfg.dModel;

      const emb = tf.gather(params.E, ids.flatten()).reshape([B,Tcur,dM]);
      let x = emb.add(params.pe.slice([0,0],[Tcur,dM]).reshape([1,Tcur,dM]));
      if (params.cfg.dropoutTrain && training) x = dropout(x, 0.1);

      for(const L of params.layers){
        let h = rmsNorm(x, L.g1);

        // Kausale Conv1D (links gepaddet)
        const K = params.CONV_KERNEL_SIZE;
        const zeroPadding = tf.zeros([B, K-1, dM]);
        const paddedH = tf.concat([zeroPadding, h], 1);
        const conv_out_full = tf.conv1d(paddedH, L.W_Conv, 1, 'valid');
        const conv_out = conv_out_full.slice([0, 0, 0], [B, Tcur, dM]);

        const gate_proj = conv_out.reshape([-1, dM]).matMul(L.W_Gate).add(L.b_Gate);
        const gate = tf.sigmoid(gate_proj).reshape([B, Tcur, dM]);

        const linear_out = tf.mul(conv_out, gate);
        x = x.add((params.cfg.dropoutTrain && training) ? dropout(linear_out, 0.1) : linear_out);

        // MLP
        let h2 = rmsNorm(x, L.g2);
        const mlp2 = h2.reshape([-1, dM]).matMul(L.W1).add(L.b1);
        const silu = tf.mul(mlp2, tf.sigmoid(mlp2));
        const mlp_out = silu.matMul(L.W2).add(L.b2).reshape([B, Tcur, dM]);
        x = x.add((params.cfg.dropoutTrain && training) ? dropout(mlp_out, 0.1) : mlp_out);
      }

      const x_2d = x.reshape([-1, dM]);
      let logits_2d = params.cfg.weightTying ? x_2d.matMul(params.E.transpose()) : x_2d.matMul(params.W_out);
      const logits = logits_2d.reshape([B, Tcur, params.cfg.V]);
      return logits.add(params.bout);
    });
  }

  function variables(){
    const vs = [E, bout];
    for (const L of params.layers){ vs.push(L.g1, L.g2, L.W_Conv, L.W_Gate, L.b_Gate, L.W1, L.b1, L.W2, L.b2); }
    vs.push(W_out);
    return vs;
  }
  return {params, forward, variables};
}

/* =================== Backend =================== */
async function setupBackend(preferGPU=true){
  try {
    if (preferGPU) {
      await tf.setBackend('webgpu');
      await tf.ready();
      logLine(`Backend: ${tf.getBackend()} (WebGPU aktiv)`);
      return;
    }
    throw new Error('Skip WebGPU');
  } catch(e){
    logLine(`WebGPU nicht aktiv (${e?.message||e}). Versuche WebGL/CPU...`);
  }
  try {
    await tf.setBackend('webgl');
    await tf.ready();
    logLine(`Backend: ${tf.getBackend()} (WebGL aktiv)`);
  } catch(e){
    await tf.setBackend('cpu');
    await tf.ready();
    logLine(`Backend: ${tf.getBackend()} (CPU aktiv)`);
  }
}

/* =================== Datenaufbereitung & Training =================== */
function buildStarts(tokens, T, valPct){
  const N = tokens.length;
  const usable = Math.max(0, N - (T+1));
  const all = new Uint32Array(usable);
  for (let i=0;i<usable;i++) all[i]=i;
  const valN = Math.floor(usable*(valPct/100));
  const trainN = usable - valN;
  return {train: all.slice(0,trainN), val: all.slice(trainN)};
}
function sampleBatch(starts, tokens, B, T){
  const X = new Int32Array(B*T), Y = new Int32Array(B*T);
  const n = starts.length;
  if (n===0) return {X,Y};
  for (let b=0;b<B;b++){
    const s = starts[(Math.random()*n)|0];
    for (let t=0;t<T;t++){
      X[b*T+t] = tokens[s+t];
      Y[b*T+t] = tokens[s+t+1];
    }
  }
  return {X,Y};
}

async function train(){
  await setupBackend(valBool('useGPU', true));
  const raw = ($('txt')?.value ?? '');
  if(!raw.trim()){ logLine('Fehler: Kein Korpus.'); return; }

  // Strikte, laute Checks + Debug:
  const Tctx = valNum('seqLen', 128, 64, 768);
  const tokOk = (STATE.tokens instanceof Uint32Array) && (STATE.tokens.length >= (Tctx+1));
  if (!STATE.atomizer || !(STATE.tokens instanceof Uint32Array)){
    dbgState('train:pre');
    logLine('Fehler: Bitte zuerst Atome lernen. (atomizer/tokens fehlen)');
    return;
  }
  if (!tokOk){
    dbgState('train:pre-too-short');
    logLine(`Fehler: Token-Länge zu klein (tokens=${STATE.tokens.length}, benötigt ≥ T+1 = ${Tctx+1}). Erhöhe Korpus oder reduziere M.`);
    return;
  }

  setButtonState('btnTrain', true, 'Trainiere…', true);
  $('btnStop').disabled = false;
  STATE.cancelTrain = false;

  try {
    const epochs = valNum('epochs', 4), B = valNum('batch', 32);
    let lr = valNum('lr', 0.002);
    const stepCap = valNum('stepCap', 400), valSplit = 10, autoLR = valBool('autoLR', true);
    const L = valNum('nLayers', 3), dModel = valNum('dModel', 256), dFF = valNum('dFF', 512);
    const weightTying = true, dropoutTrain = valBool('useDropout', false);
    const V = STATE.atomizer.vocabSize;

    if (STATE.model) STATE.model.variables().forEach(v => v.dispose());
    STATE.model = buildModel({V, dModel, dFF, nLayers: L, T: Tctx, weightTying, dropoutTrain});

    let optim = tf.train.adam(lr, 0.9, 0.999, 1e-8);

    const {train:trainStarts, val:valStarts} = buildStarts(STATE.tokens, Tctx, valSplit);
    const rawSteps = Math.max(1, Math.floor(trainStarts.length / B));
    const stepsPerEpoch = stepCap>0 ? Math.min(stepCap, rawSteps) : rawSteps;

    $('stats').textContent = `V=${V} • M=${Tctx} • B=${B} • L=${L} • d=${dModel} • dFF=${dFF} • Steps/Ep=${stepsPerEpoch}`;
    logLine(`[DBG train] starts: train=${trainStarts.length} val=${valStarts.length} rawSteps=${rawSteps} steps/Ep=${stepsPerEpoch}`);

    let bestPPL=Infinity, bad=0;
    const myModelRev = ++STATE.modelRev;

    for (let ep=0; ep<epochs; ep++){
      if (myModelRev !== STATE.modelRev || STATE.cancelTrain) break;
      logLine(`Starte Epoche ${ep+1}/${epochs} mit LR=${lr.toFixed(6)}`);
      const t0 = performance.now();
      let lossAcc=0;

      for (let s=0;s<stepsPerEpoch;s++){
        if (myModelRev !== STATE.modelRev || STATE.cancelTrain) break;
        const {X,Y} = sampleBatch(trainStarts, STATE.tokens, B, Tctx);

        const lossScalar = optim.minimize(() => {
          const x = tf.tensor2d(X, [B,Tctx], 'int32');
          const y = tf.tensor2d(Y, [B,Tctx], 'int32');
          const logits = STATE.model.forward(x, true);
          const loss = softmaxCEfromLogits(logits, y);
          return loss;
        }, true, STATE.model.variables());

        const lossArr = await lossScalar.data();
        const lossVal = lossArr[0];
        lossScalar.dispose();
        if (!Number.isFinite(lossVal)) { logLine(`FEHLER: Loss=${lossVal}. Abbruch.`); throw new Error('NaN/Inf'); }
        lossAcc += lossVal;

        if ((s % 200) === 0) logLine(`Ep ${ep+1} Step ${s}/${stepsPerEpoch} Loss=${lossVal.toFixed(4)}`);
        if ((s % 512) === 0) { const m=tf.memory(); logLine(`mem: tensors=${m.numTensors} bytes=${m.numBytes}`); }
        await tf.nextFrame();
      }
      if (myModelRev !== STATE.modelRev || STATE.cancelTrain) break;

      const t1 = performance.now();
      let nllSum = 0, tokCount = 0;
      const evalB = Math.min(B, 32);
      const evalSteps = Math.min(10, Math.max(0, Math.floor(valStarts.length / Math.max(1, evalB))));

      for (let es=0; es<evalSteps; es++){
        if (myModelRev !== STATE.modelRev || STATE.cancelTrain) break;
        const {X,Y} = sampleBatch(valStarts, STATE.tokens, evalB, Tctx);
        const valLoss = tf.tidy(() => {
          const x = tf.tensor2d(X, [evalB,Tctx], 'int32');
          const y = tf.tensor2d(Y, [evalB,Tctx], 'int32');
          return softmaxCEfromLogits(STATE.model.forward(x, false), y);
        });
        const v = (await valLoss.data())[0];
        valLoss.dispose();
        nllSum += v * (evalB*Tctx);
        tokCount += (evalB*Tctx);
        await tf.nextFrame();
      }
      if (myModelRev !== STATE.modelRev || STATE.cancelTrain) break;

      const valPPL = Math.exp(nllSum/Math.max(1,tokCount));
      const tokps = (stepsPerEpoch * B * Tctx) / Math.max(0.001, (t1-t0)/1000);
      $('metrics').innerHTML =
        `<b>Epoche ${ep+1}/${epochs}</b> &nbsp; Loss=${(lossAcc/stepsPerEpoch).toFixed(4)} &nbsp; Val PPL=${valPPL.toFixed(2)} &nbsp; ~Tok/s=${tokps.toFixed(0)} &nbsp; LR=${lr.toFixed(5)}`;
      logLine(`Ep ${ep+1}: loss=${(lossAcc/stepsPerEpoch).toFixed(4)} | ValPPL=${valPPL.toFixed(2)} | ${(t1-t0).toFixed(0)}ms | ~${tokps.toFixed(0)} tok/s`);

      if (autoLR){
        if (valPPL + 0.01 < bestPPL){ bestPPL=valPPL; bad=0; }
        else {
          bad++;
          if (bad>=2 && lr>1e-4){
            lr = Math.max(1e-4, lr*0.5);
            if (typeof optim.setLearningRate === 'function') {
              optim.setLearningRate(lr);
            } else {
              optim.dispose?.();
              optim = tf.train.adam(lr, 0.9, 0.999, 1e-8);
            }
            bad=0; logLine(`Auto-LR → ${lr.toFixed(6)}`);
          }
        }
      }
      await tf.nextFrame();
    }
    if (myModelRev === STATE.modelRev && !STATE.cancelTrain) logLine('Training abgeschlossen. Modell ist bereit zur Inferenz.');
    $('prompt').disabled = false; $('btnGen').disabled = false; $('btnExport').disabled = false;
  } catch(e){
    console.error(e); logLine('Fehler: '+(e?.message||e));
  } finally {
    setButtonState('btnTrain', false, '3. Training starten', false);
    $('btnStop').disabled = true;
    STATE.cancelTrain=false;
  }
}

/* =================== IPA -> Text Decoder (P2G) — HYBRID (Greedy + Fuzzy Fallback) =================== */

let REVERSE_DICT = null;
let REVERSE_DICT_SORTED_KEYS = []; // Für Greedy-Match (schnell)
let REVERSE_DICT_ALL_KEYS = []; // Für Fuzzy-Match (langsam)

/**
 * Standard Levenshtein-Distanz-Algorithmus.
 * Misst die "Editierdistanz" (Kosten für Einfügen, Löschen, Ersetzen)
 * zwischen zwei Strings a und b.
 */
function levenshtein(a, b) {
  const m = a.length, n = b.length;
  // Optimiere für Platz: Nur zwei Zeilen der Matrix werden benötigt
  let v0 = new Uint16Array(n + 1);
  let v1 = new Uint16Array(n + 1);

  for (let i = 0; i <= n; i++) v0[i] = i;

  for (let i = 0; i < m; i++) {
    v1[0] = i + 1;
    for (let j = 0; j < n; j++) {
      const cost = (a[i] === b[j]) ? 0 : 1;
      v1[j + 1] = Math.min(
        v1[j] + 1,      // Löschen
        v0[j + 1] + 1,  // Einfügen
        v0[j] + cost    // Ersetzen
      );
    }
    // Tausche v0 und v1
    [v0, v1] = [v1, v0];
  }
  return v0[n];
}

/**
 * Baut das Reverse-Wörterbuch (IPA -> Wort) auf,
 * inklusive der sortierten Listen für den Hybrid-Decoder.
 */
function buildReverseDict() {
  if (!STATE.dict || STATE.dict.size === 0) {
    logLine("Fehler: Wörterbuch (STATE.dict) nicht geladen für Reverse-Dict.");
    return;
  }
  
  REVERSE_DICT = new Map();
  const allKeysSet = new Set();

  for (const [word, ipa_string] of STATE.dict.entries()) {
    // 1. Speichern der vollen IPA-String-Variante (z.B. "ˈænd / ənd")
    let fullIpaKey = ipa_string.trim();
    if (!REVERSE_DICT.has(fullIpaKey)) {
        REVERSE_DICT.set(fullIpaKey, word);
    }
    allKeysSet.add(fullIpaKey);

    // 2. Speichern der einzelnen IPA-Varianten (z.B. "ˈænd" und "ənd")
    const parts = fullIpaKey.split(' / ');
    for (let ipa of parts) {
        ipa = ipa.trim();
        if (!ipa) continue;
        if (!REVERSE_DICT.has(ipa)) {
            REVERSE_DICT.set(ipa, word); // Erste Wort-Zuordnung
        }
        allKeysSet.add(ipa);
    }
  }

  // Satzzeichen als Identität hinzufügen
  const punctuation = [",", ".", "“", "”", "?", "!", ";", ":", "'", '"', "-", "–", "/", "—", " "];
  for (const p of punctuation) {
    if (!REVERSE_DICT.has(p)) REVERSE_DICT.set(p, p);
    allKeysSet.add(p);
  }

  // Sortierte Keys für Greedy-Match (längste zuerst)
  REVERSE_DICT_SORTED_KEYS = Array.from(allKeysSet);
  REVERSE_DICT_SORTED_KEYS.sort((a, b) => b.length - a.length);

  // Alle Keys für Fuzzy-Match (Reihenfolge egal)
  REVERSE_DICT_ALL_KEYS = Array.from(allKeysSet);

  logLine(`Reverse-Wörterbuch erstellt: ${REVERSE_DICT.size} Einträge. Keys (Greedy): ${REVERSE_DICT_SORTED_KEYS.length}, Keys (Fuzzy): ${REVERSE_DICT_ALL_KEYS.length}`);
}

/**
 * NEU: Fuzzy-Match-Fallback
 * Durchsucht das *gesamte* Vokabular nach der niedrigsten Levenshtein-Distanz.
 */
function findClosestPhonemeMatch(targetPhoneme) {
    if (!targetPhoneme || targetPhoneme.length < 2) return null; // Ignoriere Trivialfälle

    let minDistance = Infinity;
    let bestMatch = null;
    
    // Setze eine dynamische Schwelle:
    // Erlaube 1 Edit für 3 Zeichen, 2 Edits für 6 Zeichen, max 3 Edits.
    const threshold = Math.max(1, Math.min(3, Math.floor(targetPhoneme.length / 3)));

    for (const key of REVERSE_DICT_ALL_KEYS) {
        // Optimierung: Überspringe offensichtlich unpassende Längen
        if (Math.abs(key.length - targetPhoneme.length) > threshold) continue;
        
        const dist = levenshtein(targetPhoneme, key);

        if (dist < minDistance && dist <= threshold) {
            minDistance = dist;
            bestMatch = key;
        }
    }

    if (bestMatch) {
        // logLine(`Fuzzy-Match: "${targetPhoneme}" -> "${bestMatch}" (Dist: ${minDistance})`);
        return REVERSE_DICT.get(bestMatch); // Gib das Wort zurück
    }
    
    // logLine(`Fuzzy-Match: "${targetPhoneme}" -> Verworfen (Threshold: ${threshold})`);
    return null; // Nichts Gutes gefunden
}


/**
 * NEUE "HYBRID" DECODER-LOGIK (Greedy + Fuzzy Fallback)
 */
function decodeIPAToText(ipa_string) {
  if (!REVERSE_DICT || REVERSE_DICT_SORTED_KEYS.length === 0) {
    if (STATE.dict.size > 0) buildReverseDict();
    else return "[Fehler: Reverse-Wörterbuch nicht bereit. Bitte 'en_US.txt laden'.]";
  }
  
  let i = 0;
  const n = ipa_string.length;
  let output_words = [];
  let unknown_buffer = ""; // Sammelt Zeichen, die zu keinem Key passen

  while (i < n) {
    // 1. OOV-Token prüfen (‹...›)
    if (ipa_string.substring(i).startsWith('‹')) {
        const endIdx = ipa_string.indexOf('›', i);
        if (endIdx > i) {
            // Puffer davor per Fuzzy-Match auflösen
            if (unknown_buffer) {
                const fuzzyWord = findClosestPhonemeMatch(unknown_buffer);
                if (fuzzyWord) output_words.push(fuzzyWord);
            }
            unknown_buffer = "";
            
            const oovWord = ipa_string.substring(i + 1, endIdx);
            output_words.push(oovWord); // OOV-Wort direkt verwenden
            i = endIdx + 1;
            continue;
        }
    }
    
    // 2. Greedy-Match (Perfekter Treffer)
    let foundMatch = false;
    for (const key of REVERSE_DICT_SORTED_KEYS) {
        if (ipa_string.substring(i).startsWith(key)) {
            foundMatch = true;
            
            // Puffer davor per Fuzzy-Match auflösen
            if (unknown_buffer) {
                 const fuzzyWord = findClosestPhonemeMatch(unknown_buffer);
                if (fuzzyWord) output_words.push(fuzzyWord);
            }
            unknown_buffer = "";

            output_words.push(REVERSE_DICT.get(key)); // Das echte Wort hinzufügen
            i += key.length; // Position im String vorrücken
            break; 
        }
    }

    // 3. KEIN Greedy-Match gefunden
    if (!foundMatch) {
        // Dieses Zeichen zum Puffer hinzufügen
        unknown_buffer += ipa_string[i];
        i++; // Nur um 1 Zeichen vorrücken
    }
  }

  // 4. Letzten Puffer am String-Ende auflösen
  if (unknown_buffer) {
      const fuzzyWord = findClosestPhonemeMatch(unknown_buffer);
      if (fuzzyWord) output_words.push(fuzzyWord);
  }
  
  // 5. Array an Post-Processing übergeben
  return postProcessDecodedText(output_words);
}

/**
 * POST-PROCESSING
 * (Vereinfacht, da keine [Phonem:] Tags mehr erwartet werden)
 */
function postProcessDecodedText(words) {
  let s = "";
  let needsSpace = false;
  
  for (const word of words) {
    if (!word) continue;

    // Keine Leerstelle *vor* Satzzeichen
    if (",.?!;:”".includes(word)) {
      s = s.trim();
      s += word;
      needsSpace = true;
    } 
    // Keine Leerstelle *nach* öffnenden Anführungszeichen
    else if ("“".includes(word)) {
      if (needsSpace) s += " ";
      s += word;
      needsSpace = false;
    }
    // Bindestriche, Schrägstriche (als Wörter behandeln)
    else if (word === "-" || word === "/" || word === "—") {
        if (needsSpace) s += " ";
        s += word;
        needsSpace = true;
    }
    // Standard-Wort
    else {
      if (needsSpace) s += " ";
      s += word;
      needsSpace = true;
    }
  }
  
  // Letzte Aufräumarbeiten
  s = s.replace(/\s+([,.?!;:”])/g, '$1'); // "word ." -> "word."
  s = s.replace(/([“])\s+/g, '$1'); // "“ word" -> "“word"
  s = s.replace(/\s+/g, ' '); // Mehrfach-Leerzeichen entfernen

  return s.trim();
}

/* =================== Sampling & Inferenz =================== */
function sampleFromProbs(probs, mode, topK, topP){
  const order = Array.from(probs.keys()).sort((a,b)=>probs[b]-probs[a]);
  if (mode==='topk'){
    const K = Math.max(1, Math.min(topK, probs.length));
    const keep = order.slice(0,K);
    let s=0; for(const i of keep) s+=probs[i];
    let r=Math.random()*s;
    for(const i of keep){ r-=probs[i]; if(r<=0) return i; }
    return keep[keep.length-1];
  } else {
    const pth = clamp(topP, 0.05, 1.0);
    let cum=0, keep=[];
    for(const i of order){ keep.push(i); cum+=probs[i]; if(cum>=pth) break; }
    let s=0; for(const i of keep) s+=probs[i];
    let r=Math.random()*s;
    for(const i of keep){ r-=probs[i]; if(r<=0) return i; }
    return keep[keep.length-1];
  }
}

async function generate(){
  if (!STATE.model || !STATE.atomizer){ logLine('Bitte zuerst Atomizer + Modell trainieren/laden.'); return; }
  // Sicherstellen, dass der P2G-Decoder bereit ist
  if (!REVERSE_DICT || REVERSE_DICT_SORTED_KEYS.length === 0) {
      if (STATE.dict.size > 0) {
          buildReverseDict(); // Versuche, ihn schnell zu bauen
      } else {
          logLine("Fehler: Wörterbuch nicht geladen. Bitte 'en_US.txt laden' klicken, um Text zu dekodieren.");
          $('outText').textContent = "[Fehler: Wörterbuch nicht geladen. Bitte 'en_US.txt laden' klicken.]";
          return;
      }
  }

  $('btnGen').disabled = true; $('btnStopGen').disabled = false; $('inferStats').textContent = 'Generiere...';
  STATE.cancelGen = false;

  const mode = $('sampleMode').value, topK = valNum('topK', 64), topP = valNum('topP', 0.9), temp = valNum('temp', 0.9);
  const nGen = valNum('nGen', 200), T = STATE.model.params.cfg.T;
  const prompt = ($('prompt')?.value ?? '').trim();
  if (!prompt){ logLine('Kein Prompt.'); $('btnGen').disabled = false; $('btnStopGen').disabled = true; return; }

  const promptIPA = g2pConvert(prompt);
  let ctx = STATE.atomizer.encodeIPAtoAtoms(promptIPA, true, false);
  const t0 = performance.now();

  let outTokens = [];
  for(let step=0; step<nGen; step++){
    if (STATE.cancelGen) { logLine('Generierung abgebrochen.'); break; }
    const ctxSlice = ctx.slice(-T);
    const len=ctxSlice.length, padLen = T - len;
    const inpArr = (padLen>0) ? (new Int32Array([...Array(padLen).fill(BOS_ID), ...ctxSlice])) : new Int32Array(ctxSlice);

    const input = tf.tensor2d(inpArr,[1,T],'int32');
    const logits = STATE.model.forward(input, false);
    const lastTensor = logits.slice([0,T-1,0],[1,1,STATE.model.params.cfg.V]).reshape([STATE.model.params.cfg.V]);
    const last = await lastTensor.data();
    lastTensor.dispose(); logits.dispose(); input.dispose();

    let maxv = -Infinity; for (let i=0;i<last.length;i++) if (last[i]>maxv) maxv=last[i];
    const probs = new Float32Array(last.length);
    let Z=0; const invT = 1/clamp(temp,0.1,2.0);
    for (let i=0;i<last.length;i++){ const e=Math.exp((last[i]-maxv)*invT); probs[i]=e; Z+=e; }
    for (let i=0;i<probs.length;i++) probs[i]/=Z;

    const nxt = sampleFromProbs(probs, mode, topK, topP);
    if (nxt === EOS_ID) break;
    ctx.push(nxt); outTokens.push(nxt);

    if ((step % 8) === 0) await tf.nextFrame();
  }
  const t1 = performance.now();

  $('btnGen').disabled = false; $('btnStopGen').disabled = true;
  $('inferStats').textContent = `Tokens: ${outTokens.length} • Latenz ${(t1-t0).toFixed(1)} ms`;

  // Roh-IPA-String (wird jetzt vom Hybrid-Decoder verarbeitet)
  const genIPA = STATE.atomizer.decodeAtomsToIPA(outTokens);
  $('outIPA').textContent = genIPA; // Debug-Ansicht
  
  // NEU: Dekodierung mit dem robusten HYBRID-Decoder (Greedy + Fuzzy)
  const genText = decodeIPAToText(genIPA);
  $('outText').textContent = genText; // Saubere Text-Ansicht

  logLine(`Generiert ${outTokens.length} Atome (${(t1-t0).toFixed(0)} ms).`);
}

/* =================== Datei-Export / -Import =================== */
function ab2b64(buf){
  const bytes = new Uint8Array(buf);
  let bin=''; for (let i=0;i<bytes.length;i++) bin += String.fromCharCode(bytes[i]);
  return btoa(bin);
}
function b642ab(b64){
  const bin = atob(b64);
  const bytes = new Uint8Array(bin.length);
  for (let i=0;i<bin.length;i++) bytes[i] = bin.charCodeAt(i);
  return bytes.buffer;
}
function downloadBlob(filename, blob){
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url; a.download = filename;
  document.body.appendChild(a); a.click(); a.remove();
  URL.revokeObjectURL(url);
}

async function exportModel(){
  if (!STATE.model || !STATE.atomizer){ logLine('Export: Kein Modell/Atomizer vorhanden.'); return; }
  setButtonState('btnExport', true, 'Exportiere …', false);
  try {
    const named = {};
    for (const v of STATE.model.variables()) {
      if (!v.name) throw new Error('Variable ohne Namen.');
      if (named[v.name]) throw new Error('Duplikat: '+v.name);
      named[v.name]=v;
    }
    const {data, specs} = await tf.io.encodeWeights(named);

    const payload = {
      version: 1,
      cfg: STATE.model.params.cfg,
      weightSpecs: specs,
      weightDataB64: ab2b64(data),
      atomizer: {
        merges: STATE.atomizer.merges,
        cp2id: Object.fromEntries(STATE.atomizer.cp2id),
        id2cp: Object.fromEntries(STATE.atomizer.id2cp),
        vocabSize: STATE.atomizer.vocabSize
      }
    };
    const blob = new Blob([JSON.stringify(payload)], {type:'application/json'});
    downloadBlob('pho-atom-llm-model.json', blob);
    logLine(`Export abgeschlossen: ${(data.byteLength/1024/1024).toFixed(2)} MiB`);
  } catch(e){
    logLine('Export-Fehler: '+(e?.message||e));
  } finally {
    setButtonState('btnExport', false, 'Modell exportieren (Datei)', false);
  }
}

async function importModel(file){
  if(!file){ logLine('Import: Keine Datei gewählt.'); return; }
  const reader = new FileReader();
  reader.onload = async () => {
    try {
      const obj = JSON.parse(reader.result);
      const cfg = obj.cfg;
      if (STATE.model) STATE.model.variables().forEach(v => v.dispose());
      STATE.model = buildModel(cfg);

      const weightData = b642ab(obj.weightDataB64);
      const weightMap = await tf.io.decodeWeights(weightData, obj.weightSpecs);
      const byName = {};
      for (const v of STATE.model.variables()) byName[v.name] = v;
      for (const [name, tensor] of Object.entries(weightMap)) {
        if (byName[name]) { byName[name].assign(tensor); tensor.dispose(); }
        else tensor.dispose();
      }
      
      // NOTE: STATE.dict (Wörterbuch) wird beim Import nicht wiederhergestellt, 
      // daher muss der Benutzer es erneut laden, um den P2G-Decoder zu aktivieren.
      REVERSE_DICT = null;
      REVERSE_DICT_SORTED_KEYS = [];
      REVERSE_DICT_ALL_KEYS = [];
      
      STATE.atomizer = {
        merges: obj.atomizer.merges,
        cp2id: new Map(Object.entries(obj.atomizer.cp2id).map(([k, v]) => [Number(k), v])),
        id2cp: new Map(Object.entries(obj.atomizer.id2cp).map(([k, v]) => [Number(k), v])),
        vocabSize: obj.atomizer.vocabSize,
        encodeIPAtoAtoms: function(str, addBos, addEos) {
          const merges = this.merges;
          const cp2id = this.cp2id;
          let tokens = strToCodepoints(str).map(c => cp2id.get(c)).filter(v=>Number.isFinite(v));
          for (const m of merges){
            const {a,b,id} = m;
            const out = [];
            for (let i=0;i<tokens.length;){
              if (i<tokens.length-1 && tokens[i]===a && tokens[i+1]===b){ out.push(id); i+=2; }
              else { out.push(tokens[i]); i++; }
            }
            tokens = out;
          }
          if (addBos) tokens = [BOS_ID, ...tokens];
          if (addEos) tokens = [...tokens, EOS_ID];
          return tokens;
        },
        decodeAtomsToIPA: function(tokens) {
          const id2pair = new Map(this.merges.map(m=>[m.id,[m.a,m.b]]));
          const id2cp = this.id2cp;
          function expand(id){
            if (id===BOS_ID || id===EOS_ID) return [];
            if (id2cp.has(id)) return [ id2cp.get(id) ];
            const pr = id2pair.get(id);
            if (!pr) return [];
            return expand(pr[0]).concat(expand(pr[1]));
          }
          const cpsOut = [];
          for (const t of tokens){
            if (t===BOS_ID || t===EOS_ID) continue;
            if (id2cp.has(t)) cpsOut.push(id2cp.get(t));
            else cpsOut.push(...expand(t));
          }
          return codepointsToStr(cpsOut);
        }
      };

      $('prompt').disabled = false; $('btnGen').disabled = false; $('btnExport').disabled = false;
      logLine('Import abgeschlossen. Modell & Atomizer geladen. Bitte Wörterbuch (en_US.txt) laden, um P2G zu nutzen.');
      dbgState('after-import');
    } catch(e){
      logLine('Import-Fehler: '+(e?.message||e));
    }
  };
  reader.readAsText(file);
}

/* =================== UI =================== */
window.addEventListener('load', async ()=>{
  // Backend vorbereiten (später train() setzt erneut)
  await setupBackend(valBool('useGPU', true));

  // Buttons
  $('btnLoadDict').addEventListener('click', async ()=>{
    try{
      await loadLocalDictEN();
      buildReverseDict(); // WICHTIG: Reverse-Dict nach Laden des Forward-Dicts erstellen
      $('btnBuildIPA').disabled = false;
    }catch(e){
      logLine('Fehler beim Laden von /data/en_US.txt: '+(e?.message||e));
    }
  });

  $('btnBuildIPA').addEventListener('click', ()=>{
    const raw=($('txt')?.value??'').trim();
    if(!raw){ logLine('Kein Text.'); return; }
    if(STATE.dict.size === 0) { logLine('Fehler: Wörterbuch nicht geladen. Bitte zuerst "en_US.txt laden" klicken.'); return; }
    try{
      const ipa=g2pConvert(raw);
      STATE.ipa = ipa;
      $('kpiIPA').textContent = `IPA: ${ipa.length} Zeichen`;
      $('btnTrainAtoms').disabled = false;
      logLine('1. G2P → IPA fertig.');
      dbgState('after-g2p');
    }catch(e){
      logLine('G2P-Fehler: '+(e?.message||e));
    }
  });

  $('btnTrainAtoms').addEventListener('click', async ()=>{
    const raw=($('txt')?.value??'').trim();
    if(!raw){ logLine('Kein Text.'); return; }
    if(!STATE.ipa){ logLine('Bitte zuerst G2P → IPA ausführen.'); return; }
    const atomVocab = valNum('atomVocab', 512);
    const T = valNum('seqLen', 128);

    $('btnTrainAtoms').disabled = true; $('btnBuildIPA').disabled = true;
    $('inferStats').textContent = '2. Atomizer wird trainiert...';

    try {
      const atomizer = await buildAtomBPE(STATE.ipa, atomVocab);
      const atomIds = atomizer.encodeIPAtoAtoms(STATE.ipa, true, true);
      STATE.atomizer = atomizer;
      STATE.tokens = new Uint32Array(atomIds);

      const atomCount = STATE.tokens.length;
      $('kpiAtoms').textContent = `Atome (inkl. BOS/EOS): ${atomCount}`;
      const roughComp = (STATE.ipa.length>0) ? (STATE.ipa.length / atomCount).toFixed(2) : '–';
      $('kpiComp').textContent = `Kompression: ${roughComp}×`;
      logLine(`PhenomEncoder abgeschlossen. Vocab=${STATE.atomizer.vocabSize}. Tokens=${atomCount}`);
      dbgState('after-atomizer');

      // Training nur freigeben, wenn genug Tokens für (T+1)
      if (STATE.tokens.length >= (T+1)) {
        $('btnTrain').disabled = false;
      } else {
        $('btnTrain').disabled = true;
        logLine(`Hinweis: Tokens=${STATE.tokens.length} < T+1=${T+1}. Bitte M reduzieren oder mehr Text bereitstellen.`);
      }
      $('inferStats').textContent = 'Atome fertig. Bereit zum Training.';
    } catch (e) {
      logLine(`Fehler beim Atomizer-Training: ${e.message}`);
    } finally {
      $('btnTrainAtoms').disabled = false; $('btnBuildIPA').disabled = false;
    }
  });
  
  // Enter-zum-Senden für das Prompt-Feld
  $('prompt').addEventListener('keydown', (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault(); // Verhindert Zeilenumbruch
        if (!$('btnGen').disabled) {
            generate(); // Löst Generierung aus
        }
    }
  });

  $('btnTrain').addEventListener('click', train);
  $('btnGen').addEventListener('click', generate);
  $('btnStop').addEventListener('click', ()=>{ STATE.cancelTrain=true; $('btnStop').disabled = true; logLine('Training gestoppt (am Step-/Epochenende).'); });
  $('btnStopGen').addEventListener('click', ()=>{ STATE.cancelGen=true; $('btnStopGen').disabled = true; });

  $('btnDbgDump').addEventListener('click', ()=>{
    dbgState('manual');
    if (STATE.tokens instanceof Uint32Array){
      const T = valNum('seqLen', 128);
      const starts = buildStarts(STATE.tokens, T, 10);
      logLine(`[DBG dump] seqLen=${T} tokens=${STATE.tokens.length} starts.train=${starts.train.length} starts.val=${starts.val.length}`);
      if (STATE.atomizer) logLine(`[DBG dump] merges=${STATE.atomizer.merges.length} exampleMerge=${JSON.stringify(STATE.atomizer.merges[0]||null)}`);
    }
  });

  $('btnClear').addEventListener('click', ()=>{
    STATE.dict = new Map();
    STATE.ipa = '';
    STATE.atomizer = null;
    STATE.tokens = null;
    REVERSE_DICT = null; // Wichtig: Reverse-Dict auch löschen
    REVERSE_DICT_SORTED_KEYS = [];
    REVERSE_DICT_ALL_KEYS = [];
    if (STATE.model) { STATE.model.variables().forEach(v=>v.dispose()); STATE.model=null; }
    $('kpiDict').textContent='Wörterbuch: –';
    $('kpiIPA').textContent='IPA: –';
    $('kpiAtoms').textContent='Atome: –';
    $('kpiComp').textContent='Kompression: –';
    $('outIPA').textContent='';
    $('outText').textContent='';
    $('btnBuildIPA').disabled = true;
    $('btnTrainAtoms').disabled = true;
    $('btnTrain').disabled = true;
    $('btnExport').disabled = true;
    $('prompt').disabled = true;
    $('btnGen').disabled = true;
    logLine('Zustand zurückgesetzt.');
  });

  $('fileImport').addEventListener('change', (e)=> {
      if(e.target.files?.[0]) importModel(e.target.files[0]);
      e.target.value = null; // Erlaube Re-Import derselben Datei
  });

  $('sampleMode').addEventListener('change', ()=>{
    const m=$('sampleMode').value;
    $('topK').disabled = (m!=='topk'); $('topP').disabled=(m!=='topp');
  });
});
</script>


</body></html>
